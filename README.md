# FPI-MPI Hand Detection

SAM 2 + MediaPipe entegrasyonu ile gerÃ§ek zamanlÄ± el tespiti ve nesne segmentasyonu.

## âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Otomatik Kurulum (Ã–nerilen)

**Windows:**
```bash
git clone https://github.com/omerkurueks/fpi-mpi-hand-detection.git
cd fpi-mpi-hand-detection
quick_setup.bat
```

**Linux/Mac:**
```bash
git clone https://github.com/omerkurueks/fpi-mpi-hand-detection.git
cd fpi-mpi-hand-detection
chmod +x quick_setup.sh
./quick_setup.sh
```

**Python Script (Ã‡apraz Platform):**
```bash
git clone https://github.com/omerkurueks/fpi-mpi-hand-detection.git
cd fpi-mpi-hand-detection
python setup.py
```

### Ä°lk Test
```bash
# Virtual environment aktifleÅŸtir
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# SAM 2 test
python tests/test_sam2_final.py

# HÄ±zlÄ± MediaPipe test
python tests/test_mediapipe_fast.py
```

## ğŸ¯ Ã–zellikler

- **SAM 2 (Segment Anything Model 2)** ile zero-shot object segmentation
- **MediaPipe** ile real-time hand detection ve tracking
- **RTSP stream** desteÄŸi ile IP kamera entegrasyonu
- **CUDA acceleration** desteÄŸi
- **Real-time processing** optimizasyonlarÄ±

## ğŸš€ Kurulum (Yeni Bilgisayarda)

### AdÄ±m 1: Sistem Gereksinimleri
```bash
# Python 3.8+ gerekli
python --version

# CUDA kontrolÃ¼ (GPU kullanÄ±mÄ± iÃ§in)
nvidia-smi
```

### AdÄ±m 2: Repository Clone
```bash
git clone https://github.com/omerkurueks/fpi-mpi-hand-detection.git
cd fpi-mpi-hand-detection
```

### AdÄ±m 3: Python Virtual Environment
```bash
# Virtual environment oluÅŸtur
python -m venv .venv

# AktifleÅŸtir
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
```

### AdÄ±m 4: Temel Dependencies
```bash
# PyTorch CUDA version (Ã¶nemli!)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# DiÄŸer dependencies
pip install -r requirements.txt
```

### AdÄ±m 5: SAM 2 Kurulumu
```bash
# SAM 2 zaten projede var, sadece install et
cd sam2_official
pip install -e .
cd ..
```

### AdÄ±m 6: Model DosyalarÄ±nÄ± Ä°ndir
```bash
# Model klasÃ¶rÃ¼ oluÅŸtur
mkdir models
mkdir models\sam2

# SAM 2.1 Hiera Large model indir (898MB)
# Windows PowerShell:
Invoke-WebRequest -Uri "https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt" -OutFile "models\sam2\sam2.1_hiera_large.pt"

# Linux/Mac:
# wget https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt -O models/sam2/sam2.1_hiera_large.pt
```

### AdÄ±m 7: Kurulum Testi
```bash
# CUDA ve dependencies kontrolÃ¼
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"

# SAM 2 testi
python tests\test_sam2_final.py

# MediaPipe testi
python tests\test_mediapipe_fast.py
```
# Download from: https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt
```

### 5. Config Setup
```bash
mkdir -p configs/sam2.1
# Download config: https://github.com/facebookresearch/sam2/blob/main/sam2_configs/sam2.1_hiera_l.yaml
```

## ğŸ® KullanÄ±m

### ğŸ¯ Ana Uygulama (main.py)

```bash
# Webcam ile Ã§alÄ±ÅŸtÄ±r (varsayÄ±lan)
python main.py

# HÄ±zlÄ± mod (sadece MediaPipe - 30+ FPS)
python main.py --mode fast

# Tam mod (SAM 2 + MediaPipe - 5-10 FPS)
python main.py --mode full

# RTSP kamera ile
python main.py --rtsp "rtsp://user:pass@ip:port/stream"

# Video dosyasÄ± ile
python main.py --video "video.mp4"
```

### âŒ¨ï¸ Kontroller
- **ESC**: Ã‡Ä±kÄ±ÅŸ
- **SPACE**: Pause/Resume
- **S**: Screenshot kaydet

### ğŸ§ª Test DosyalarÄ±
```bash
# SAM 2 kurulum testi
python tests/test_sam2_final.py

# HÄ±zlÄ± MediaPipe testi
python tests/test_mediapipe_fast.py

# RTSP stream testi
python tests/test_sam2_rtsp.py
```

## ğŸ“‹ Sistem Gereksinimleri

### Minimum
- Python 3.8+
- CUDA 11.8+ (GPU acceleration iÃ§in)
- 8GB RAM
- 4GB GPU memory

### Ã–nerilen
- Python 3.9+
- CUDA 12.1+
- 16GB RAM
- 8GB+ GPU memory (RTX 3060 veya Ã¼zeri)

## ğŸ”§ KonfigÃ¼rasyon

### GPU AyarlarÄ±
```python
# CUDA kullanÄ±mÄ±
device = "cuda" if torch.cuda.is_available() else "cpu"

# Model paths
SAM2_CHECKPOINT = "models/sam2/sam2.1_hiera_large.pt"
SAM2_CONFIG = "configs/sam2.1/sam2.1_hiera_l.yaml"
```

### RTSP Stream
```python
# RTSP URL Ã¶rneÄŸi
RTSP_URL = "rtsp://username:password@ip_address:port/stream"
```

## ğŸ“Š Performans

### Test SonuÃ§larÄ±
- **MediaPipe Only**: 30+ FPS (640x480)
- **SAM 2 + MediaPipe**: 5-10 FPS (416x240, optimized)
- **Full Resolution SAM 2**: 1-3 FPS (640x480)

### Optimizasyon Stratejileri
- Frame skipping (her N frame'de SAM 2)
- DÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k processing
- ROI-based segmentation
- Model caching

## ğŸ› ï¸ Troubleshooting

### Import Errors (SAM2MediaPipeDetector bulunamadÄ±)
```bash
# Debug script Ã§alÄ±ÅŸtÄ±r
python debug_imports.py

# YaygÄ±n Ã§Ã¶zÃ¼mler:
# 1. Virtual environment aktif mi?
.venv\Scripts\activate  # Windows

# 2. SAM 2 kurulumu
cd sam2_official
pip install -e .
cd ..

# 3. Dependencies tekrar yÃ¼kle
pip install -r requirements.txt --force-reinstall
```

### CUDA Errors
```bash
# PyTorch CUDA version check
python -c "import torch; print(torch.cuda.is_available())"

# CUDA-enabled PyTorch install
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### SAM 2 Import Errors
```bash
# SAM 2 reinstall
cd sam2_official
pip install -e . --force-reinstall
```

### OpenCV RTSP Issues
```bash
# OpenCV with FFMPEG support
pip uninstall opencv-python
pip install opencv-python-headless
```

**KullanÄ±m AlanlarÄ±:**
- EndÃ¼striyel kalite kontrol sÃ¼reÃ§lerinde iÅŸÃ§i davranÄ±ÅŸ analizi
- Laboratuvar ortamlarÄ±nda araÅŸtÄ±rmacÄ± aktivite takibi
- EÄŸitim videolarÄ±nda Ã¶ÄŸrenci etkileÅŸim analizi
- Retail ortamlarÄ±nda mÃ¼ÅŸteri Ã¼rÃ¼n inceleme davranÄ±ÅŸlarÄ±

## ğŸ—ï¸ Sistem Mimarisi

### Temel BileÅŸenler

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Video Input   â”‚â”€â”€â”€â–¶â”‚   Hand Detection  â”‚â”€â”€â”€â–¶â”‚ Object Detectionâ”‚
â”‚  (USB/RTSP/MP4) â”‚    â”‚   (MediaPipe)     â”‚    â”‚     (YOLO)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                          â”‚
                                â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Event Logging   â”‚â—€â”€â”€â”€â”‚  State Machine    â”‚â—€â”€â”€â”€â”‚ Motion Analysis â”‚
â”‚  (JSONL/CSV)    â”‚    â”‚   (FSM Logic)     â”‚    â”‚ (Optical Flow)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   API Endpoints   â”‚
                       â”‚    (FastAPI)      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Veri AkÄ±ÅŸÄ±

1. **GÃ¶rÃ¼ntÃ¼ GiriÅŸ** â†’ Video akÄ±ÅŸÄ±ndan frame-by-frame okuma
2. **El Tespiti** â†’ MediaPipe ile gerÃ§ek zamanlÄ± el landmark'larÄ±
3. **Nesne Tespiti** â†’ YOLO ile Ã§evredeki nesnelerin tespiti
4. **EÅŸleÅŸtirme** â†’ IoU/mesafe tabanlÄ± el-nesne eÅŸleÅŸtirmesi
5. **Hareket Analizi** â†’ Optik akÄ±ÅŸ ile hareket metriklerinin hesaplanmasÄ±
6. **Durum YÃ¶netimi** â†’ FSM ile inceleme davranÄ±ÅŸÄ±nÄ±n tespiti
7. **KayÄ±t & Raporlama** â†’ Event'lerin kaydedilmesi ve API Ã¼zerinden sunumu

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Ã–nkoÅŸullar

```bash
# Python 3.10+ gerekli
python --version

# Git ile proje klonlama
git clone <repository-url>
cd fpi-mpi-hand-detection
```

### Kurulum

#### 1. Virtual Environment OluÅŸturma

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux/macOS  
python -m venv venv
source venv/bin/activate
```

#### 2. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme

```bash
# Temel baÄŸÄ±mlÄ±lÄ±klar
pip install -r requirements.txt

# CUDA destekli PyTorch (GPU kullanÄ±mÄ± iÃ§in)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

#### 3. KonfigÃ¼rasyon

```bash
# VarsayÄ±lan konfigÃ¼rasyonlarÄ± kopyalama
cp configs/logic.yaml.example configs/logic.yaml
cp configs/model.yaml.example configs/model.yaml
cp configs/data.yaml.example configs/data.yaml
```

### ğŸ³ Docker ile Kurulum

```bash
# Tek komutla baÅŸlatma
docker-compose up api

# Arkaplanda Ã§alÄ±ÅŸtÄ±rma
docker-compose up -d api

# DiÄŸer servisler
docker-compose --profile train up training    # Model eÄŸitimi
docker-compose --profile eval up evaluation   # DeÄŸerlendirme
docker-compose --profile cache up redis       # Cache sistemi
```

## ğŸ“‹ KullanÄ±m KÄ±lavuzu

### 1. GerÃ§ek ZamanlÄ± Ä°nference

```bash
# Webcam ile canlÄ± tespit
python scripts/infer.py --source 0 --config configs/logic.yaml

# Video dosyasÄ± ile tespit
python scripts/infer.py --source video.mp4 --config configs/logic.yaml --output results/

# RTSP stream ile tespit
python scripts/infer.py --source rtsp://admin:HeysemAI246@192.168.150.59 --config configs/logic.yaml
```

### 2. API Server

```bash
# FastAPI server baÅŸlatma
uvicorn src.api.server:app --host 0.0.0.0 --port 8000

# API dÃ¶kÃ¼mantasyonu
# http://localhost:8000/docs
```

#### API Endpoints

- **POST** `/infer` - Frame-by-frame inference
- **GET** `/events` - Event geÃ§miÅŸini alma
- **GET** `/events/current` - Aktif event'ler
- **GET** `/health` - Sistem saÄŸlÄ±k durumu
- **GET** `/stats` - Ä°statistikler

### 3. Model EÄŸitimi

```bash
# YOLO modeli eÄŸitimi
python scripts/train.py --config configs/model.yaml --data data/yolo_dataset/

# EÄŸitim parametreleri
python scripts/train.py --epochs 100 --batch-size 16 --imgsz 640 --device 0
```

### 4. DeÄŸerlendirme

```bash
# Model performans deÄŸerlendirmesi
python scripts/eval.py --predictions data/predictions/ --ground-truth data/ground_truth/

# Temporal IoU analizi
python scripts/eval.py --temporal-analysis --window-size 30
```

## âš™ï¸ KonfigÃ¼rasyon

### Ana KonfigÃ¼rasyon (configs/logic.yaml)

```yaml
# Video giriÅŸ ayarlarÄ±
video:
  source: 0                    # 0=webcam, 'video.mp4', 'rtsp://...'
  fps: 30
  resolution: [640, 480]
  buffer_size: 1

# El tespit ayarlarÄ±
hands:
  max_num_hands: 2
  min_detection_confidence: 0.7
  min_tracking_confidence: 0.5
  model_complexity: 1

# Nesne tespit ayarlarÄ±  
objects:
  model_path: "models/yolo_objects.pt"
  confidence_threshold: 0.5
  iou_threshold: 0.45
  device: "auto"               # "cpu", "cuda", "auto"

# Hareket analizi
motion:
  method: "farneback"          # "farneback", "dis", "lucas_kanade"
  scale: 0.5
  flow_threshold: 2.0

# Ä°nceleme davranÄ±ÅŸ tespiti
inhand:
  matching_strategy: "center_iou"
  iou_threshold: 0.3
  match_threshold: 50.0
  min_confidence: 0.5

# Durum makinesi
fsm:
  start_threshold: 2.0         # Hareket eÅŸiÄŸi (inceleme baÅŸlangÄ±cÄ±)
  stop_threshold: 1.0          # Hareket eÅŸiÄŸi (inceleme bitiÅŸi) 
  min_frames_start: 3          # Minimum frame sayÄ±sÄ± (baÅŸlangÄ±Ã§)
  min_frames_stop: 3           # Minimum frame sayÄ±sÄ± (bitiÅŸ)
  grace_frames: 5              # Tespit kaybÄ± toleransÄ±
  confidence_threshold: 0.7    # Minimum gÃ¼ven skoru

# GÃ¶rselleÅŸtirme
visualization:
  show_hands: true
  show_objects: true
  show_flow: false
  show_tracks: true
  font_size: 0.6
  line_thickness: 2
```

### Model KonfigÃ¼rasyonu (configs/model.yaml)

```yaml
# YOLO eÄŸitim ayarlarÄ±
model:
  architecture: "yolov8n"      # yolov8n, yolov8s, yolov8m, yolov8l, yolov8x
  pretrained: true
  classes: 80                  # COCO sÄ±nÄ±f sayÄ±sÄ±

training:
  epochs: 100
  batch_size: 16
  imgsz: 640
  optimizer: "SGD"
  lr0: 0.01
  momentum: 0.937
  weight_decay: 0.0005
  
augmentation:
  hsv_h: 0.015
  hsv_s: 0.7
  hsv_v: 0.4
  degrees: 0.0
  translate: 0.1
  scale: 0.5
  shear: 0.0
  perspective: 0.0
  flipud: 0.0
  fliplr: 0.5
  mosaic: 1.0
  mixup: 0.0
```

## ğŸ“Š Veri FormatlarÄ±

### Event Logging (JSONL)

```json
{
  "event_id": "evt_20240101_123456_001",
  "track_id": 1,
  "start_time": 1704110096.123,
  "end_time": 1704110098.456,
  "duration": 2.333,
  "hand_bbox": [120, 150, 200, 250],
  "object_bbox": [130, 160, 190, 230],
  "confidence": 0.85,
  "motion_metrics": {
    "flow_magnitude": 2.5,
    "centroid_movement": 1.2,
    "area_ratio": 1.1,
    "bbox_change": 0.8
  },
  "metadata": {
    "hand_type": "Right",
    "grip_strength": 0.7,
    "object_class": "bottle"
  }
}
```

### YOLO Dataset Format

```
data/yolo_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”‚   â””â”€â”€ img_002.jpg
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ img_003.jpg
â”‚       â””â”€â”€ img_004.jpg
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ img_001.txt    # class x_center y_center width height
â”‚   â”‚   â””â”€â”€ img_002.txt
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ img_003.txt
â”‚       â””â”€â”€ img_004.txt
â””â”€â”€ data.yaml
```

## ğŸ§ª Test Etme

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±rma
python -m pytest tests/ -v

# Belirli modÃ¼l testleri
python -m pytest tests/test_fsm.py -v
python -m pytest tests/test_inhand.py -v
python -m pytest tests/test_motion.py -v

# Coverage raporu
python -m pytest tests/ --cov=src --cov-report=html
```

## ğŸ“ˆ Performans Metrikleri

### Sistem PerformansÄ±

- **FPS**: Saniyede iÅŸlenen frame sayÄ±sÄ±
- **Latency**: Frame iÅŸleme sÃ¼resi (ms)
- **Memory**: RAM kullanÄ±mÄ± (MB)
- **CPU/GPU**: Ä°ÅŸlemci kullanÄ±m yÃ¼zdesi

### Tespit PerformansÄ±

- **Hand Detection**: MediaPipe accuracy/precision
- **Object Detection**: YOLO mAP@0.5, mAP@0.5:0.95
- **Tracking**: MOT metrics (MOTA, MOTP, IDF1)
- **Temporal IoU**: Zaman bazlÄ± overlap analizi

### DeÄŸerlendirme Ã–rneÄŸi

```bash
# Performans raporu oluÅŸturma
python scripts/eval.py --predictions results/ --ground-truth annotations/ --report performance_report.html

# GerÃ§ek zamanlÄ± metrikler
curl http://localhost:8000/stats
```

## ğŸ”§ GeliÅŸmiÅŸ KullanÄ±m

### Custom Object Detection

```python
# Kendi YOLO modelinizi kullanma
from src.detect.yolo_wrapper import YOLOWrapper

yolo = YOLOWrapper("path/to/your/model.pt")
detections = yolo.detect(frame, confidence=0.5)
```

### Custom Motion Analysis

```python
# Kendi hareket analizÃ¶rÃ¼nÃ¼zÃ¼ oluÅŸturma
from src.motion.optical_flow import OpticalFlowAnalyzer

analyzer = OpticalFlowAnalyzer(config)
flow = analyzer.compute_frame(frame)
metrics = analyzer.analyze_region(bbox, prev_bbox)
```

### API Integration

```python
import requests

# Inference API kullanÄ±mÄ±
with open("frame.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8000/infer",
        files={"frame": f},
        data={"timestamp": time.time()}
    )
    
result = response.json()
print(f"Detected {len(result['tracks'])} hand-object pairs")
```

## ğŸ› ï¸ Troubleshooting

### YaygÄ±n Problemler

#### 1. MediaPipe Import HatasÄ±
```bash
# Ã‡Ã¶zÃ¼m
pip uninstall mediapipe
pip install mediapipe
```

#### 2. CUDA Memory Error
```bash
# GPU memory temizleme
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

#### 3. OpenCV Video Capture
```bash
# Codec yÃ¼kleme (Linux)
sudo apt-get install ffmpeg
```

#### 4. Performance Issues
```python
# KonfigÃ¼rasyonda optimizasyon
motion:
  scale: 0.25        # Daha dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k
  
hands:
  model_complexity: 0  # Daha hÄ±zlÄ± model
```

### Debug Mode

```bash
# Verbose logging
python scripts/infer.py --source 0 --debug --log-level DEBUG

# Visualization ile debug
python scripts/infer.py --source 0 --show-debug --save-debug-frames
```

## ğŸ“ Proje YapÄ±sÄ±

```
fpi-mpi-hand-detection/
â”œâ”€â”€ ğŸ“ src/                    # Ana kaynak kodlarÄ±
â”‚   â”œâ”€â”€ ğŸ“ api/               # FastAPI endpoints
â”‚   â”œâ”€â”€ ğŸ“ detect/            # Tespit modÃ¼lleri (hands, objects)
â”‚   â”œâ”€â”€ ğŸ“ logic/             # Ä°ÅŸ mantÄ±ÄŸÄ± (FSM, inhand)
â”‚   â”œâ”€â”€ ğŸ“ motion/            # Hareket analizi
â”‚   â”œâ”€â”€ ğŸ“ io/                # I/O iÅŸlemleri
â”‚   â”œâ”€â”€ ğŸ“ viz/               # GÃ¶rselleÅŸtirme
â”‚   â”œâ”€â”€ ğŸ“„ config.py          # KonfigÃ¼rasyon yÃ¶netimi
â”‚   â””â”€â”€ ğŸ“„ pipeline.py        # Ana pipeline
â”œâ”€â”€ ğŸ“ configs/               # KonfigÃ¼rasyon dosyalarÄ±
â”œâ”€â”€ ğŸ“ scripts/               # CLI araÃ§larÄ±
â”œâ”€â”€ ğŸ“ tools/                 # Veri dÃ¶nÃ¼ÅŸÃ¼m araÃ§larÄ±
â”œâ”€â”€ ğŸ“ tests/                 # Unit testler
â”œâ”€â”€ ğŸ“ data/                  # Veri dizini
â”‚   â”œâ”€â”€ ğŸ“ raw/              # Ham veri
â”‚   â”œâ”€â”€ ğŸ“ processed/        # Ä°ÅŸlenmiÅŸ veri
â”‚   â”œâ”€â”€ ğŸ“ events/           # Event loglarÄ±
â”‚   â””â”€â”€ ğŸ“ models/           # EÄŸitilmiÅŸ modeller
â”œâ”€â”€ ğŸ“ docs/                  # DokÃ¼mantasyon
â”œâ”€â”€ ğŸ“„ requirements.txt       # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ ğŸ“„ Dockerfile            # Docker image tarifi
â”œâ”€â”€ ğŸ“„ docker-compose.yml    # Multi-service orchestration
â””â”€â”€ ğŸ“„ README.md             # Bu dosya
```

## ğŸš€ GeniÅŸleme Yol HaritasÄ±

### KÄ±sa Vadeli (1-3 ay)
- [x] **MVP Tamamlama**: Temel tespit ve FSM sistemi
- [x] **API Endpoints**: RESTful API ile entegrasyon
- [x] **Docker Support**: Containerized deployment
- [ ] **Model Optimization**: ONNX/TensorRT conversion
- [ ] **Multi-camera Support**: Ã‡oklu kamera desteÄŸi
- [ ] **Real-time Dashboard**: Web-based monitoring

### Orta Vadeli (3-6 ay)
- [ ] **Advanced Tracking**: DeepSORT/ByteTrack entegrasyonu
- [ ] **3D Hand Pose**: MediaPipe World landmarks
- [ ] **Action Recognition**: Temporal CNN models
- [ ] **Data Augmentation**: Synthetic data generation
- [ ] **Edge Deployment**: Jetson/RaspberryPi support
- [ ] **Cloud Integration**: AWS/Azure deployment

### Uzun Vadeli (6+ ay)
- [ ] **Transformer Models**: ViT-based detection
- [ ] **Federated Learning**: Distributed training
- [ ] **AR Visualization**: Real-time AR overlay
- [ ] **Behavior Analytics**: Advanced pattern recognition
- [ ] **Multi-modal Fusion**: Audio-visual analysis
- [ ] **Domain Adaptation**: Industry-specific models

## ğŸ¤ KatkÄ± SaÄŸlama

### Development Setup

```bash
# Development dependencies
pip install -r requirements-dev.txt

# Pre-commit hooks
pre-commit install

# Code formatting
black src/ tests/
isort src/ tests/

# Linting
flake8 src/ tests/
mypy src/
```

### Contribution Guidelines

1. **Fork** projeyi
2. **Feature branch** oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. **Commit** deÄŸiÅŸikliklerinizi (`git commit -m 'Add amazing feature'`)
4. **Push** branch'e (`git push origin feature/amazing-feature`)
5. **Pull Request** aÃ§Ä±n

### Code Standards

- **Python**: PEP 8 uyumlu
- **Type Hints**: TÃ¼m fonksiyonlarda
- **Docstrings**: Google style
- **Tests**: %90+ coverage hedefi
- **Logging**: Structured logging with loguru

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±nÄ±z.

## ğŸ™ TeÅŸekkÃ¼rler

- **MediaPipe**: Google's hand detection framework
- **YOLOv8**: Ultralytics object detection
- **OpenCV**: Computer vision operations
- **FastAPI**: Modern web framework
- **PyTorch**: Deep learning framework

## ğŸ“ Ä°letiÅŸim

- **Proje**: [GitHub Repository](https://github.com/your-username/fpi-mpi-hand-detection)
- **Issues**: [GitHub Issues](https://github.com/your-username/fpi-mpi-hand-detection/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-username/fpi-mpi-hand-detection/discussions)

---

**ğŸ” Elde Nesne Ä°nceleme Tespiti** - GeliÅŸmiÅŸ bilgisayar gÃ¶rmesi ile el-nesne etkileÅŸim analizi

*Bu README, projenin kapsamlÄ± kullanÄ±m kÄ±lavuzu ve teknik dokÃ¼mantasyonudur. GÃ¼ncel bilgiler iÃ§in repository'yi takip edin.*
